{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**CNN model for cifar10 dataset, using a custom model (data in memory) with and without data augmentation**"
      ],
      "metadata": {
        "id": "9vhHE0j64W8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load and Preprocess the CIFAR-10 Dataset**"
      ],
      "metadata": {
        "id": "mGjkpvqb4c47"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VkVo0iKF4EKV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Normalize the pixel values to be between 0 and 1\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eogC3iPD4Ji7",
        "outputId": "f70c1512-3cff-46de-90eb-7479c0a341a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a Custom CNN Model**"
      ],
      "metadata": {
        "id": "_idnZkYA4gcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_custom_cnn():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "vXn5hYLZ4MeX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the Model Without Data Augmentation**"
      ],
      "metadata": {
        "id": "AuJFh0Fm4nQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model_without_augmentation = create_custom_cnn()\n",
        "\n",
        "# Train the model\n",
        "history_without_augmentation = model_without_augmentation.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=10,\n",
        "    validation_data=(test_images, test_labels),\n",
        "    batch_size=64\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qEzuWW44OhO",
        "outputId": "4b524a62-c707-4a42-d899-a1f9ee5eb08e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.4459 - loss: 1.5752 - val_accuracy: 0.5787 - val_loss: 1.1723\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6552 - loss: 0.9874 - val_accuracy: 0.6315 - val_loss: 1.0451\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7170 - loss: 0.8116 - val_accuracy: 0.6494 - val_loss: 1.0190\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7546 - loss: 0.7037 - val_accuracy: 0.6867 - val_loss: 0.9107\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.6097 - val_accuracy: 0.6501 - val_loss: 1.0735\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8150 - loss: 0.5314 - val_accuracy: 0.6899 - val_loss: 0.9242\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8326 - loss: 0.4806 - val_accuracy: 0.6745 - val_loss: 1.0534\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8539 - loss: 0.4241 - val_accuracy: 0.6880 - val_loss: 1.0025\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8685 - loss: 0.3824 - val_accuracy: 0.7074 - val_loss: 0.9412\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8891 - loss: 0.3246 - val_accuracy: 0.6880 - val_loss: 1.0493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the Model With Data Augmentation**"
      ],
      "metadata": {
        "id": "GFg5S-g-4rM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data generator with data augmentation\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Create the model\n",
        "model_with_augmentation = create_custom_cnn()\n",
        "\n",
        "# Train the model using the data generator\n",
        "history_with_augmentation = model_with_augmentation.fit(\n",
        "    datagen.flow(train_images, train_labels, batch_size=64),\n",
        "    epochs=10,\n",
        "    validation_data=(test_images, test_labels),\n",
        "    steps_per_epoch=len(train_images) // 64\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3ComTJO4QlS",
        "outputId": "65afe883-0312-455d-e7d7-f07efc79b237"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 52ms/step - accuracy: 0.4041 - loss: 1.6814 - val_accuracy: 0.5518 - val_loss: 1.2587\n",
            "Epoch 2/10\n",
            "\u001b[1m  1/781\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5312 - loss: 1.0895"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.5312 - loss: 1.0895 - val_accuracy: 0.5306 - val_loss: 1.3254\n",
            "Epoch 3/10\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 50ms/step - accuracy: 0.5857 - loss: 1.1640 - val_accuracy: 0.6130 - val_loss: 1.1101\n",
            "Epoch 4/10\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.5156 - loss: 1.3375 - val_accuracy: 0.6143 - val_loss: 1.1041\n",
            "Epoch 5/10\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 48ms/step - accuracy: 0.6314 - loss: 1.0279 - val_accuracy: 0.6711 - val_loss: 0.9424\n",
            "Epoch 6/10\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 0.6406 - loss: 1.0797 - val_accuracy: 0.6693 - val_loss: 0.9477\n",
            "Epoch 7/10\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 48ms/step - accuracy: 0.6691 - loss: 0.9460 - val_accuracy: 0.6930 - val_loss: 0.8740\n",
            "Epoch 8/10\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.6250 - loss: 1.0686 - val_accuracy: 0.6928 - val_loss: 0.8748\n",
            "Epoch 9/10\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 48ms/step - accuracy: 0.6920 - loss: 0.8879 - val_accuracy: 0.6016 - val_loss: 1.2231\n",
            "Epoch 10/10\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 0.7031 - loss: 0.9386 - val_accuracy: 0.6033 - val_loss: 1.2008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare the Results**"
      ],
      "metadata": {
        "id": "SomjeV9E4ys1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate both models on the test dataset\n",
        "test_loss_without_aug, test_acc_without_aug = model_without_augmentation.evaluate(test_images, test_labels, verbose=2)\n",
        "test_loss_with_aug, test_acc_with_aug = model_with_augmentation.evaluate(test_images, test_labels, verbose=2)\n",
        "\n",
        "print(f\"Test accuracy without data augmentation: {test_acc_without_aug:.4f}\")\n",
        "print(f\"Test accuracy with data augmentation: {test_acc_with_aug:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-p0BGdV4ShW",
        "outputId": "a95afa18-201e-4646-9429-305364e8121d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - 3ms/step - accuracy: 0.6880 - loss: 1.0493\n",
            "313/313 - 1s - 2ms/step - accuracy: 0.6033 - loss: 1.2008\n",
            "Test accuracy without data augmentation: 0.6880\n",
            "Test accuracy with data augmentation: 0.6033\n"
          ]
        }
      ]
    }
  ]
}